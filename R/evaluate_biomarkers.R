#' Evaluate Discovered Biomarkers Across Multiple Datasets and Groups
#'
#' Reads biomarker definitions from a discovery results file and evaluates their
#' performance (Repeatability, Separation, Sample Size Estimate) on specified
#' datasets and diagnostic groups (CU/CI), optionally calculating confidence intervals.
#' Evaluation is performed dataset-by-dataset, group-by-group.
#'
#' @param discovery_results_csv_path Character string. Path to the input CSV file
#'   containing biomarker discovery results (typically generated by `run_experiments`).
#'   Expected columns include `regs_numerator`, `regs_denominator`, `var_composition`,
#'   and ideally identifiers like `discovery_dataset`, `experiment_tag`.
#' @param prepared_data_list List. The output from `preprocess_datasets()`,
#'   containing filtered data for multiple datasets (e.g., `list(ADNI=list(data=..., data_suv_bi=...), MAYO=...)`).
#' @param config List. The loaded main configuration object (output from
#'   `check_and_prepare_data$config`). Must contain sections like
#'   `preprocessing`, `model_equations`, `power_params`.
#' @param datasets_to_evaluate Character vector. Names of the datasets within
#'   `prepared_data_list` to evaluate the biomarkers on. Defaults to using all
#'   datasets present in `prepared_data_list`.
#' @param groups_to_evaluate Character vector. Groups ("CU", "CI") to evaluate
#'   within each dataset. Defaults to `c("CU", "CI")`.
#' @param calculate_ci Logical. If `TRUE`, calculate and return bootstrap/estimated
#'   95% confidence intervals using `.feval_group_95CI`. Defaults to `FALSE`.
#' @param nsim Integer. Number of bootstrap simulations if `calculate_ci` is `TRUE`.
#'   Defaults to 100. Ignored if `calculate_ci` is `FALSE`.
#' @param output_evaluation_csv_path Character string or NULL. If provided, the full
#'   path to save the *evaluation* results table as a *new* CSV file. If the file
#'   exists, it will be overwritten. Directory created if needed.
#' @param id_col Character string. Name of the unique individual identifier column,
#'   used for merging and checking data. Fetched from config if possible, defaults
#'   to "RID".
#' @param verbose Logical. Print progress messages? Defaults to TRUE.
#'
#' @return A data frame containing the evaluation results. Each row corresponds to
#'   one discovered biomarker evaluated on one specific dataset and group. Columns
#'   include identifiers from the input CSV, evaluation context (dataset, group),
#'   evaluation status, and the calculated metrics (Rep, SepAB, SSE, plus CIs
#'   if requested). Returns `NULL` if the input CSV cannot be read or essential
#'   data is missing.
#'
#' @details
#' Workflow:
#' 1. Reads the `discovery_results_csv_path`.
#' 2. Iterates through each dataset in `datasets_to_evaluate`.
#' 3. For each dataset, identifies available features and prepares clinical data.
#' 4. Iterates through each group in `groups_to_evaluate`.
#' 5. For each dataset/group combination, iterates through each row (discovered biomarker)
#'    in the discovery results file.
#' 6. Validates that the biomarker's required regions exist in the current dataset.
#' 7. Reconstructs a 'chromosome' vector based on the biomarker's definition and
#'    the available features for the current dataset.
#' 8. Calls internal `.calculate_cvr` to compute the biomarker value.
#' 9. Merges the calculated value with the clinical data.
#' 10. Checks for sufficient data in the specific dataset/group combination.
#' 11. Calls `.feval_group` (or `.feval_group_95CI`) to get performance metrics.
#' 12. Records the metrics along with discovery identifiers and evaluation context.
#' 13. Combines all results into a single data frame after all loops complete.
#' 14. Optionally saves the results table to `output_evaluation_csv_path`.
#'
#' @export
#' @importFrom utils read.csv head 
#' @importFrom readr read_csv write_csv 
#' @importFrom dplyr bind_rows select all_of left_join filter n_distinct between 
#' @importFrom stringr str_split 
#' @importFrom rlang `%||%` .data sym is_scalar_character is_scalar_logical is_scalar_integerish 
#' @importFrom stats setNames median quantile IQR sd na.omit aggregate as.formula
#' @importFrom lme4 lmerControl
#' @importFrom longpower lmmpower
#' @importFrom methods is
#' @importFrom progress progress_bar
evaluate_biomarkers <- function(discovery_results_csv_path,
                                prepared_data_list,
                                config,
                                datasets_to_evaluate = names(prepared_data_list),
                                groups_to_evaluate = c("CU", "CI"),
                                calculate_ci = FALSE,
                                nsim = 100,
                                output_evaluation_csv_path = NULL,
                                id_col = NULL, # Get from config later
                                verbose = TRUE) {
  
  # --- Input Validation ---
  stopifnot(
    rlang::is_scalar_character(discovery_results_csv_path),
    file.exists(discovery_results_csv_path),
    is.list(prepared_data_list), length(prepared_data_list) > 0,
    is.list(config),
    is.character(datasets_to_evaluate), length(datasets_to_evaluate) > 0,
    is.character(groups_to_evaluate), all(groups_to_evaluate %in% c("CU", "CI")),
    rlang::is_scalar_logical(calculate_ci),
    rlang::is_scalar_integerish(nsim), nsim > 1,
    is.null(output_evaluation_csv_path) || rlang::is_scalar_character(output_evaluation_csv_path),
    is.null(id_col) || rlang::is_scalar_character(id_col),
    rlang::is_scalar_logical(verbose)
  )
  # Check datasets exist
  missing_dsets <- setdiff(datasets_to_evaluate, names(prepared_data_list))
  datasets_to_evaluate <- intersect(datasets_to_evaluate, names(prepared_data_list))
  if (length(missing_dsets) > 0) message("Datasets not found in prepared_data_list: ", paste(missing_dsets, collapse=", "), "\nProceeding with ", datasets_to_evaluate)
  # Get ID col from config or use default
  id_col <- id_col %||% config$preprocessing$id_column %||% "RID"
  ignore_cols <- config$preprocessing$ignore_columns %||% "idx"
  
  # --- Load Discovery Results ---
  message("--- Loading Discovery Results ---")
  discovery_results_df <- try(readr::read_csv(discovery_results_csv_path, show_col_types = FALSE), silent = TRUE)
  if (inherits(discovery_results_df, "try-error")) {
    stop("Failed to read discovery results CSV: ", discovery_results_csv_path, "\nError: ", conditionMessage(attr(discovery_results_df,"condition")))
  }
  if (nrow(discovery_results_df) == 0) {
    warning("Discovery results CSV is empty: ", discovery_results_csv_path, call. = FALSE); return(NULL)
  }
  message(sprintf("Loaded %d discovered biomarker results to evaluate.", nrow(discovery_results_df)))
  
  # Check for essential columns from discovery results
  required_discovery_cols <- c("regs_numerator", "regs_denominator", "var_composition") # Add others used for ID if needed
  missing_discovery_cols <- setdiff(required_discovery_cols, names(discovery_results_df))
  if (length(missing_discovery_cols) > 0) {
    stop("Input discovery CSV is missing required columns: ", paste(missing_discovery_cols, collapse=", "))
  }
  
  # required_cols
  required_cols <- c(id_col, "time", "DX", "AB", "value") # Ensure these align with formulas/logic

  
  # --- Prepare Common Elements (Formulas, Control) ---
  all_power_params <- config$power_params
  eq_all_str <- config$model_equations$eq_all_string
  eq_group_str <- config$model_equations$eq_group_string
  if(is.null(eq_all_str) || is.null(eq_group_str)) stop("Missing formula strings in config.")
  eq_all <- try(stats::as.formula(eq_all_str)); if(inherits(eq_all, "try-error")) stop("Invalid eq_all_str")
  eq_group <- try(stats::as.formula(eq_group_str)); if(inherits(eq_group, "try-error")) stop("Invalid eq_group_str")
  lmer_control <- lme4::lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE,
                                    check.conv.singular = "ignore",
                                    optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  
  # --- Initialize List to Store All Evaluation Results ---
  all_evaluation_results <- list()
  result_counter <- 0
  
  # --- progress bar ---
  # Multicohort take as many time as the number of cohorts
  total_iterations <- length(datasets_to_evaluate) * length(groups_to_evaluate) * nrow(discovery_results_df)
  message(sprintf("Performing %d evaluations (%d datasets, %d groups, %d biomarkers).", total_iterations, length(datasets_to_evaluate), length(groups_to_evaluate), nrow(discovery_results_df)))
  pb <- progress_bar$new(
    format = "Progress [:bar] :percent (:current/:total) | ETA: :eta ",
    total = total_iterations,
    clear = FALSE,
    width = 50
  )
  
  # --- Loop 1: Through Datasets to Evaluate On ---
  message("\n--- Starting Biomarker Evaluation ---")
  for (eval_dset_name in datasets_to_evaluate) {
    if(verbose) message(sprintf("\nProcessing Dataset: %s", eval_dset_name))
    current_eval_data_list <- prepared_data_list[[eval_dset_name]]
    
    # --- Prepare data for this dataset once ---
    if (!"data" %in% names(current_eval_data_list) || !is.data.frame(current_eval_data_list$data) ||
        !"data_suv_bi" %in% names(current_eval_data_list) || !is.data.frame(current_eval_data_list$data_suv_bi)) {
      warning(sprintf("Skipping dataset '%s': Missing 'data' or 'data_suv_bi'.", eval_dset_name), call. = FALSE)
      next # Skip to next dataset
    }
    data_clinical <- current_eval_data_list$data
    data_suv <- current_eval_data_list$data_suv_bi
    available_features <- setdiff(names(data_suv), c(id_col, ignore_cols)) # Features available in THIS dataset
    required_clinical_cols <- c(id_col, "time", "DX", "AB") # Align with .feval_group needs
    if (length(available_features) == 0) {
      warning(sprintf("Skipping dataset '%s': No valid feature columns found in 'data_suv_bi'.", eval_dset_name), call. = FALSE)
      next
    }
    if (!all(required_clinical_cols %in% names(data_clinical))) {
      warning(sprintf("Skipping dataset '%s': Clinical data missing required columns: %s.",
                      eval_dset_name, paste(setdiff(required_clinical_cols, names(data_clinical)), collapse=", ")), call. = FALSE)
      next
    }
    
    # --- Loop 2: Through Groups to Evaluate ---
    for (eval_group in groups_to_evaluate) {
      if(verbose) message(sprintf("  Evaluating Group: %s", eval_group))
      target_group_dx_val <- if(eval_group == "CI") 1L else 0L
      
      # --- Pre-Biomarker Loop Data Sufficiency Check *** ---
      min_rows_threshold <- 30
      min_group_members_threshold <- 20
      eval_status_group <- "Pending" # Status for this group overall
      
      # Check the clinical data prepared for this dataset
      group_subset_check <- data_clinical |>
        dplyr::filter(.data$DX == target_group_dx_val, .data$AB == TRUE, !is.na(.data$AB))
      
      n_group_rows_check <- nrow(group_subset_check)
      n_group_ids_check <- dplyr::n_distinct(group_subset_check[[id_col]])
      
      if(n_group_rows_check < min_rows_threshold || n_group_ids_check < min_group_members_threshold ) {
        warning(sprintf("Skipping ALL biomarkers for Dataset '%s', Group '%s': Insufficient initial data rows (%d) or unique IDs (%d) for reliable metrics evaluation. Min required: %d rows, %d IDs.",
                        eval_dset_name, eval_group, n_group_rows_check, n_group_ids_check, min_rows_threshold, min_group_members_threshold), call.=FALSE)
        eval_status_group <- "Insufficient Data Pre-Check"
        
        # # --- Optionally log skipped rows for *all* biomarkers for this group/dataset ---
        # # This creates placeholder rows indicating the skip reason for clarity in output CSV
        # if (!is.null(output_evaluation_csv_path)) {
        #   message(sprintf("    -> Logging skipped status for %d biomarkers...", nrow(discovery_results_df)))
        #   # Define NA metrics structure
        #   if (calculate_ci) metrics_na <- stats::setNames(rep(NA_real_, 9), c("Rep", "Rep.lower", "Rep.upper", "SepAB", "SepAB.lower", "SepAB.upper", "SSE", "SSE.lower", "SSE.upper"))
        #   else metrics_na <- stats::setNames(rep(NA_real_, 3), c("Rep", "SepAB", "SSE"))
        #   metrics_df_na <- as.data.frame(as.list(metrics_na))
        #   
        #   # Loop through biomarkers just to create the log entries
        #   for (i_skip in seq_len(nrow(discovery_results_df))) {
        #     biomarker_row_skip <- discovery_results_df[i_skip, , drop = FALSE]
        #     discovery_info_skip <- biomarker_row_skip |>
        #       dplyr::select(dplyr::any_of(c("timestamp", "experiment_tag", "discovery_dataset",
        #                                     "group_evaluated", "bilateral", "var_composition",
        #                                     "fitness_value", "regs_numerator", "regs_denominator",
        #                                     "reference_vector", "ga_seed_used")))
        #     result_counter <- result_counter + 1
        #     all_evaluation_results[[result_counter]] <- dplyr::bind_cols(
        #       discovery_info_skip,
        #       data.frame(evaluation_dataset = eval_dset_name,
        #                  evaluation_group = eval_group,
        #                  evaluation_status = eval_status_group, # Log skip reason
        #                  stringsAsFactors = FALSE),
        #       metrics_df_na
        #     )
        #   } # End loop logging skipped biomarkers
        # } # End if logging skipped rows
        
        # Advance progress bar
        pb$tick(nrow(discovery_results_df))
        
        next # Skip to the next group (or dataset if this was the last group)
      }
      # --- *** END: Pre-Biomarker Loop Data Sufficiency Check *** ---
      
      # --- Loop 3: Through Each Discovered Biomarker (Row in CSV) ---
      for (i in seq_len(nrow(discovery_results_df))) {
        # tick now in case a biomarker is skipped
        pb$tick()
        
        biomarker_row <- discovery_results_df[i, , drop = FALSE]
        # Use a unique identifier for the biomarker if available (e.g., from discovery_dataset + experiment_tag)
        # biomarker_id_str <- paste(biomarker_row$discovery_dataset %||% "NA", biomarker_row$experiment_tag %||% i, sep="_")
        # if(verbose) message(sprintf("    Biomarker %d/%d (%s)...", i, nrow(discovery_results_df), biomarker_id_str))
        
        # Extract definition
        regs_num_str <- biomarker_row$regs_numerator[[1]] %||% ""
        regs_den_str <- biomarker_row$regs_denominator[[1]] %||% ""
        var_comp <- biomarker_row$var_composition[[1]]
        
        if (!nzchar(regs_num_str) || !nzchar(regs_den_str) || is.na(var_comp)) {
          # warning(sprintf("Skipping biomarker row %d on %s/%s: Missing/invalid definition.", i, eval_dset_name, eval_group), call. = FALSE)
          next # Skip this biomarker if definition is bad
        }
        
        # Parse regions
        num_regions <- stringr::str_split(regs_num_str, ", ")[[1]]
        den_regions <- stringr::str_split(regs_den_str, ", ")[[1]]
        num_regions <- num_regions[nzchar(num_regions)]
        den_regions <- den_regions[nzchar(den_regions)]
        
        if (length(num_regions) == 0 || length(den_regions) == 0) {
          # warning(sprintf("Skipping biomarker row %d on %s/%s: Parsed definition empty.", i, eval_dset_name, eval_group), call. = FALSE)
          next # Skip this biomarker
        }
        
        # --- Check if required regions exist in THIS dataset ---
        missing_num <- setdiff(num_regions, available_features)
        missing_den <- setdiff(den_regions, available_features)
        
        if (length(missing_num) > 0 || length(missing_den) > 0) {
          # warning(sprintf("Skipping biomarker row %d on %s/%s: Required regions not found.", i, eval_dset_name, eval_group), call. = FALSE)
          # Optionally log which regions were missing
          next # Skip this biomarker for this dataset
        }
        
        # --- Reconstruct Chromosome for .calculate_cvr ---
        chromosome <- rep(1.5, length(available_features))
        chromosome[available_features %in% num_regions] <- 0.5
        chromosome[available_features %in% den_regions] <- 2.5
        
        # --- Calculate CVR Value ---
        calculated_value <- tryCatch({
          .calculate_cvr(
            chromosome = chromosome,
            dataset_cohort_data = current_eval_data_list,
            features = available_features,
            var_composition = var_comp,
            fixed_numerator_regs = NULL, # Not applicable here
            fixed_denominator_regs = NULL,
            verbose = FALSE
          )
        }, error = function(e) { NULL })
        
        if (is.null(calculated_value) || all(is.na(calculated_value))) {
          # warning(sprintf("Skipping biomarker row %d on %s/%s: .calculate_cvr failed.", i, eval_dset_name, eval_group), call.=FALSE)
          # Store a row indicating CVR failure? Or just skip? Let's skip.
          next
        }
        
        # --- Prepare data for evaluation ---
        eval_data <- data_clinical # Start fresh for each biomarker
        if (nrow(eval_data) != length(calculated_value)) {
          warning(sprintf("Skipping biomarker row %d on %s/%s: Row mismatch CVR/clinical (%d vs %d).",
                          i, eval_dset_name, eval_group, length(calculated_value), nrow(eval_data)), call. = FALSE)
          next
        }
        eval_data$value <- calculated_value # Add the calculated biomarker value
        eval_data <- stats::na.omit(eval_data[, required_cols, drop = FALSE])
        
        # --- Initialize metrics & status ---
        metrics <- NULL
        eval_status <- "Pending"
        
        # --- Check data sufficiency for this group ---
        min_rows_threshold <- 30
        min_group_members_threshold <- 20
        group_subset <- eval_data |> dplyr::filter(.data$DX == target_group_dx_val, .data$AB == TRUE)
        n_group_rows <- nrow(group_subset)
        n_group_ids <- dplyr::n_distinct(group_subset[[id_col]])
        
        if(n_group_rows < min_rows_threshold || n_group_ids < min_group_members_threshold ) {
          # warning(sprintf("Biomarker row %d on %s/%s: Insufficient data rows (%d) or unique IDs (%d).",
          #                 i, eval_dset_name, eval_group, n_group_rows, n_group_ids), call.=FALSE)
          eval_status <- "Insufficient Data"
          if (calculate_ci) metrics <- stats::setNames(rep(NA_real_, 9), c("Rep", "Rep.lower", "Rep.upper", "SepAB", "SepAB.lower", "SepAB.upper", "SSE", "SSE.lower", "SSE.upper"))
          else metrics <- stats::setNames(rep(NA_real_, 3), c("Rep", "SepAB", "SSE"))
        } else {
          # --- Call appropriate evaluation function ---
          eval_func <- if(calculate_ci) .feval_group_95CI else .feval_group
          eval_args <- list(
            data = eval_data, # Use the data with 'value' column added
            group = eval_group,
            eq_all = eq_all, 
            eq_group = eq_group,
            all_power_params = all_power_params,
            lmer_control = lmer_control
          )
          if(calculate_ci) eval_args$nsim <- nsim
          
          metrics_result <- try(do.call(eval_func, eval_args), silent = TRUE)
          
          if (inherits(metrics_result, "try-error")) {
            warning(sprintf("Biomarker row %d on %s/%s: Evaluation function failed. Error: %s",
                            i, eval_dset_name, eval_group, conditionMessage(attr(metrics_result, "condition"))), call.=FALSE)
            eval_status <- "Metrics Calculation Error"
            if (calculate_ci) metrics <- stats::setNames(rep(NA_real_, 9), c("Rep", "Rep.lower", "Rep.upper", "SepAB", "SepAB.lower", "SepAB.upper", "SSE", "SSE.lower", "SSE.upper"))
            else metrics <- stats::setNames(rep(NA_real_, 3), c("Rep", "SepAB", "SSE"))
          } else if (anyNA(metrics_result)) {
            # warning(sprintf("Biomarker row %d on %s/%s: Evaluation function returned NA values.", i, eval_dset_name, eval_group), call.=FALSE)
            eval_status <- "Metrics Calculation NA"
            metrics <- metrics_result # Store the NAs
          } else {
            eval_status <- "Success"
            metrics <- metrics_result
          }
        } # End if sufficient data
        
        # --- Store Result Row ---
        result_counter <- result_counter + 1
        # Combine discovery info with evaluation info and metrics
        discovery_info <- biomarker_row |>
          dplyr::select(dplyr::any_of(c("timestamp", "experiment_tag", "discovery_dataset",
                                        "group_evaluated", "bilateral", "var_composition",
                                        "fitness_value", "regs_numerator", "regs_denominator",
                                        "reference_vector", "ga_seed_used"))) # Select relevant discovery columns
        
        metrics_df <- as.data.frame(as.list(metrics))
        
        all_evaluation_results[[result_counter]] <- dplyr::bind_cols(
          discovery_info,
          data.frame(evaluation_dataset = eval_dset_name,
                     evaluation_group = eval_group,
                     evaluation_status = eval_status,
                     stringsAsFactors = FALSE),
          metrics_df
        )
        
      } # End loop over biomarkers (CSV rows)
    } # End loop over groups
  } # End loop over datasets
  
  # --- Combine All Results ---
  if (length(all_evaluation_results) == 0) {
    warning("No evaluation results were generated.", call. = FALSE)
    final_results_df <- data.frame() # Return empty data frame
  } else {
    final_results_df <- dplyr::bind_rows(all_evaluation_results)
    message(sprintf("\n--- Evaluation Complete: Generated %d result rows. ---", nrow(final_results_df)))
  }
  
  # --- Save Final Table (Optional) ---
  if (!is.null(output_evaluation_csv_path)) {
    tryCatch({
      output_dir <- dirname(output_evaluation_csv_path)
      if (!dir.exists(output_dir)) {
        message("Creating output directory for evaluation CSV: ", output_dir)
        dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)
      }
      if(dir.exists(output_dir)){
        readr::write_csv(final_results_df, output_evaluation_csv_path, na = "NA") # Write NA for missing
        message("Evaluation results saved to: ", output_evaluation_csv_path)
      } else {
        warning("Failed to create output directory '", output_dir, "'. Cannot write evaluation CSV.", call.=FALSE)
      }
    }, error = function(e) {
      warning(sprintf("Failed to write evaluation results to '%s': %s", output_evaluation_csv_path, e$message), call. = FALSE)
    })
  }
  
  invisible(final_results_df)
}
